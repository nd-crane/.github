# Trusted AI
A brief summary of the Trusted AI Research at University of Notre Dame for Crane Surface Warfare Center can be found below.

Further information can be found at https://nd-crane.github.io

## The Challenge
<img src="./profile/images/attack.png" alt="drawing" width="800"/>

## The Objective: 
Develop a systematic test and evaluation framework for AI that addresses the following
* Human Trust of AI/ML
* Measures, Metrics, and Testing
* Data Source Bias and Modularity
* Cybersecurity + Risk Modeling
* Developing AI Workforce and Talent

## Technical Approach:
<img src="./profile/images/circle.png" alt="drawing" width="400"/>

## Circle of Trust
For Trusted AI to succeed we need to develop a “circle of trust” where all AI activities follow best practices based on our 6 dimensions.
* Safety and Robustness
* Fairness
* Privacy
* Sustainability
* Accountability
* Explainability

# The nd-crane organization hosts repositories for the following TAI projects.

## Human-machine Pairing for Trustworthy AI: (Adam Czajka)
Develop a framework for human-machine supervision cycle, with its validation in the realm of computer vision and security areas, which will allow both sides – humans and AI systems –to interact, learn from each other and, as an overarching goal, increase the trustworthiness in AI systems.

## Trust and Verifiability in AI: (Adam Czajka)
Develop an approach for testing the verifiability of AI, which is designed to primarily work with black-box models, but will support white-box testing also. To support today’s warfighter, where solutions are based on AI models in embedded systems, effective black box tools are needed to help establish the verifiability of the AI, even when solutions are proprietary, and neither the training data or the algorithms are available.

## Statistical Analysis and Measurement of Neural Networks: (Chris Sweet)
Investigate and develop a statistical and computational framework to test, analyze, and enhance Neural Network models to help identify and alleviate potential failures and weaknesses, including those that occur naturally and those deliberately created by adversaries. 

## Knowledge Representation and Engineering: (Paul Brenner)

Identifying the complex causes of potential mission or weapon system failure (or success) and determining effective responses to preventing (or ensuring) such requires leveraging best in class data analytics techniques on rapidly growing, but often poorly structured, data. To facilitate this approach, natural language processing (NLP) and related machine learning tools such as knowledge graphs can be harnessed to gain insight and answer these critical questions. Further information can be found at https://nd-crane.github.io.       

## Framework Infrastructure Development: (Charles Vardeman II)
The T&E Web UI and Framework provides a graphical user interface and backend framework for connecting the various components and toolboxes together into a single coherent system.  This component essentially provides a sandbox for Crane T&E to interact with, to define information surrounding an AI instance, to document and define the T&E activities undertaken, and to help automate testing. Further information can be found at https://nd-crane.github.io and https://la3d.github.io/nuggets/posts/frameworks-reflection/.

